# LiteLLM Model Configuration
# For text/PDF processing (supports any LiteLLM-compatible model)
# https://docs.litellm.ai/docs/providers
# Default: groq/llama-3.3-70b-versatile
MODEL_TEXT=""

# For image/vision processing (supports any LiteLLM-compatible vision model)
# Default: groq/llama-4-scout-17b-16e-instruct
MODEL_VISION=""

# Examples
# export MODEL_TEXT=ollama/llama3.2
# export MODEL_VISION=ollama/moondream
#
# export MODEL_TEXT=gpt-4o-mini
# export MODEL_VISION=gpt-4o

# API Keys for LLM Providers
# Unless using Ollama, you'll need at least one API key based on the models
# selected above
GROQ_API_KEY=""
OPENAI_API_KEY=""
ANTHROPIC_API_KEY=""
AZURE_OPENAI_API_KEY=""
GOOGLE_API_KEY=""
MISTRAL_API_KEY=""
OPENROUTER_API_KEY=""
PERPLEXITY_API_KEY=""
XAI_API_KEY=""

# Local Model Configuration (when using Ollama)
# Default: http://localhost:11434
OLLAMA_API_BASE=""

# AgentOps for tracing and debug (optional)
AGENTOPS_API_KEY=""
